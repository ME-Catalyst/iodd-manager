# Monitoring and Observability

Monitor Greenstack in production for reliability and performance.

## Monitoring Stack

Recommended monitoring tools:

- **Prometheus**: Metrics collection
- **Grafana**: Visualization and dashboards
- **Loki**: Log aggregation
- **Alertmanager**: Alert management

## Application Metrics

### Health Check Endpoint

Built-in health check:

```bash
curl http://localhost:8000/api/health
```

**Response:**

```json
{
  "status": "healthy",
  "version": "2.0.0",
  "database": "connected",
  "timestamp": "2025-01-11T10:00:00Z"
}
```

### Custom Metrics

Add Prometheus metrics to your application:

```python
# metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Request metrics
http_requests_total = Counter(
    'greenstack_http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration = Histogram(
    'greenstack_http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

# Business metrics
iodd_imports_total = Counter(
    'greenstack_imports_total',
    'Total IODD imports',
    ['status']  # success, failed
)

devices_total = Gauge(
    'greenstack_devices_total',
    'Total devices in database'
)

adapters_generated_total = Counter(
    'greenstack_adapters_generated_total',
    'Total adapters generated',
    ['platform']
)
```

```python
# api.py - Add metrics to endpoints
@app.post("/api/iodd/upload")
async def upload_iodd(file: UploadFile):
    with http_request_duration.labels('POST', '/api/iodd/upload').time():
        try:
            result = import_iodd(file)
            iodd_imports_total.labels('success').inc()
            devices_total.inc()
            return result
        except Exception as e:
            iodd_imports_total.labels('failed').inc()
            raise

@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    return Response(
        generate_latest(),
        media_type="text/plain"
    )
```

## Prometheus Setup

### Install Prometheus

```bash
# Download Prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
cd prometheus-*
```

### Configure Prometheus

**prometheus.yml:**

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'greenstack'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

### Run Prometheus

```bash
./prometheus --config.file=prometheus.yml
```

Access at: http://localhost:9090

## Grafana Setup

### Install Grafana

```bash
# Ubuntu/Debian
sudo apt-get install -y software-properties-common
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
sudo apt-get update
sudo apt-get install grafana

# Start Grafana
sudo systemctl start grafana-server
sudo systemctl enable grafana-server
```

Access at: http://localhost:3000 (default: admin/admin)

### Add Prometheus Data Source

1. Configuration → Data Sources → Add data source
2. Select Prometheus
3. URL: http://localhost:9090
4. Save & Test

### Create Dashboard

**Dashboard Panels:**

1. **HTTP Requests Rate**
```promql
rate(greenstack_http_requests_total[5m])
```

2. **Request Duration (P95)**
```promql
histogram_quantile(0.95, rate(greenstack_http_request_duration_seconds_bucket[5m]))
```

3. **Total Devices**
```promql
greenstack_devices_total
```

4. **Import Success Rate**
```promql
rate(greenstack_imports_total{status="success"}[5m]) /
rate(greenstack_imports_total[5m]) * 100
```

5. **Adapters Generated by Platform**
```promql
rate(greenstack_adapters_generated_total[5m])
```

## Log Aggregation

### Structured Logging

```python
import logging
import json

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            'timestamp': self.formatTime(record),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
        return json.dumps(log_data)

# Configure logging
handler = logging.FileHandler('app.log')
handler.setFormatter(JSONFormatter())
logging.root.addHandler(handler)
```

### Loki Setup

**docker-compose.yml:**

```yaml
version: '3.8'

services:
  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yaml
      - loki-data:/loki

  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log:ro
      - ./promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml

volumes:
  loki-data:
```

**promtail-config.yml:**

```yaml
server:
  http_listen_port: 9080

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: greenstack
    static_configs:
      - targets:
          - localhost
        labels:
          job: greenstack
          __path__: /opt/greenstack/data/logs/*.log
```

Add Loki to Grafana:

1. Configuration → Data Sources → Add data source
2. Select Loki
3. URL: http://localhost:3100
4. Save & Test

## Alerting

### Alertmanager Setup

**alertmanager.yml:**

```yaml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'email'

receivers:
  - name: 'email'
    email_configs:
      - to: 'admin@example.com'

  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/xxx/yyy/zzz'
        channel: '#alerts'
```

### Alert Rules

**alerts.yml:**

```yaml
groups:
  - name: greenstack_alerts
    interval: 30s
    rules:
      # Service down
      - alert: ServiceDown
        expr: up{job="greenstack"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Greenstack is down"
          description: "Greenstack has been down for more than 1 minute"

      # High error rate
      - alert: HighErrorRate
        expr: rate(greenstack_http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} req/s"

      # Import failures
      - alert: ImportFailures
        expr: rate(greenstack_imports_total{status="failed"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High import failure rate"
          description: "Import failure rate is {{ $value }} per second"

      # Slow requests
      - alert: SlowRequests
        expr: histogram_quantile(0.95, rate(greenstack_http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow request latency"
          description: "95th percentile latency is {{ $value }}s"

      # Disk space low
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/opt/greenstack"} / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low"
          description: "Only {{ $value | humanizePercentage }} space remaining"
```

Add to **prometheus.yml:**

```yaml
rule_files:
  - "alerts.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['localhost:9093']
```

## Uptime Monitoring

### External Monitoring Services

- **UptimeRobot**: https://uptimerobot.com
- **Pingdom**: https://www.pingdom.com
- **StatusCake**: https://www.statuscake.com

### Simple Health Check Script

```bash
#!/bin/bash
# check-health.sh

URL="https://yourdomain.com/api/health"
TIMEOUT=10

response=$(curl -s -o /dev/null -w "%{http_code}" --max-time $TIMEOUT $URL)

if [ "$response" = "200" ]; then
    echo "✓ Service is healthy"
    exit 0
else
    echo "✗ Service is unhealthy (HTTP $response)"
    # Send alert (email, Slack, etc.)
    exit 1
fi
```

```bash
# Add to crontab (every 5 minutes)
*/5 * * * * /opt/greenstack/scripts/check-health.sh
```

## Performance Monitoring

### Application Performance Monitoring (APM)

**Option 1: OpenTelemetry**

```python
from opentelemetry import trace
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

# Initialize tracer
tracer = trace.get_tracer(__name__)

# Instrument FastAPI
FastAPIInstrumentor.instrument_app(app)

# Custom spans
with tracer.start_as_current_span("import_iodd"):
    result = import_iodd_file(file_path)
```

**Option 2: Sentry**

```python
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

sentry_sdk.init(
    dsn="https://xxx@sentry.io/yyy",
    integrations=[FastApiIntegration()],
    traces_sample_rate=1.0
)
```

### Database Query Monitoring

```python
import time
import logging

def log_query_time(func):
    """Decorator to log database query time"""
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start
        if duration > 1.0:  # Log slow queries
            logging.warning(f"Slow query: {func.__name__} took {duration:.2f}s")
        return result
    return wrapper

@log_query_time
def get_device(vendor_id, device_id):
    # Database query
    pass
```

## Resource Monitoring

### System Metrics

**Node Exporter (Prometheus):**

```bash
# Install Node Exporter
wget https://github.com/prometheus/node_exporter/releases/download/v1.6.0/node_exporter-1.6.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.tar.gz
cd node_exporter-*
./node_exporter
```

Add to **prometheus.yml:**

```yaml
scrape_configs:
  - job_name: 'node'
    static_configs:
      - targets: ['localhost:9100']
```

**Grafana Dashboard:**

Import dashboard ID 1860 (Node Exporter Full) from grafana.com

## Dashboard Templates

### Greenstack Dashboard

```json
{
  "dashboard": {
    "title": "Greenstack Overview",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [{
          "expr": "rate(greenstack_http_requests_total[5m])"
        }]
      },
      {
        "title": "Response Time P95",
        "targets": [{
          "expr": "histogram_quantile(0.95, rate(greenstack_http_request_duration_seconds_bucket[5m]))"
        }]
      },
      {
        "title": "Total Devices",
        "targets": [{
          "expr": "greenstack_devices_total"
        }]
      },
      {
        "title": "Import Success Rate",
        "targets": [{
          "expr": "rate(greenstack_imports_total{status='success'}[5m]) / rate(greenstack_imports_total[5m]) * 100"
        }]
      }
    ]
  }
}
```

## Best Practices

1. **Monitor what matters**: Focus on key business metrics
2. **Set meaningful alerts**: Avoid alert fatigue
3. **Use SLOs**: Define service level objectives
4. **Regular reviews**: Review dashboards and metrics weekly
5. **Test alerts**: Verify alerts fire correctly
6. **Document runbooks**: Create incident response procedures

## Troubleshooting

### Metrics Not Appearing

```bash
# Check metrics endpoint
curl http://localhost:8000/metrics

# Check Prometheus targets
# Visit: http://localhost:9090/targets
```

### High Memory Usage

```bash
# Check process memory
ps aux | grep python

# Reduce API workers
# Edit .env: API_WORKERS=2
```

### Alert Not Firing

```bash
# Check alert rules
# Visit: http://localhost:9090/alerts

# Check Alertmanager
# Visit: http://localhost:9093
```

## Next Steps

- **[Production Deployment](production.md)** - Production setup
- **[Docker Deployment](docker.md)** - Container monitoring
- **[Environment Configuration](environment.md)** - Configuration management
